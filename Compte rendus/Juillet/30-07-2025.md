---
tags:
  - note-quotidienne
Auteur: Esteban Carrasco
Fichier mère: "[[Compte rendus - Juillet]]"
---

> [!todo]+ To do list
> - [ ] 


## Réalisé
- modification des fonctions de tracé pour mettre une couleur unique par track sur base de la documentation (IA inefficace)
- génération de [[ByteTrack11.mp4]] avec [[Programmes/ByteTrack/VuPhan/adaptation.py|adaptation.py]] : mêmes hyperparamètres que [[ByteTrack9.mp4]] et ajout des couleurs distinctes par id. Génération d'une palette par Chat GPT.
```python
#Palette = ColorPalette.from_matplotlib(palette_name, 50)
Palette = ColorPalette.from_hex(GPT_PALETTE)
self.trace_annotator.color = self.bbox_annotator.color = self.label_annotator.color = Palette

frame_traced = self.trace_annotator.annotate(frame.copy(), detections=detections, custom_color_lookup=ColorLookup.TRACK)
frame_boxes = self.bbox_annotator.annotate(frame_traced, detections=detections, custom_color_lookup=ColorLookup.TRACK)
```

- Correction de la fonction `from_matplotlib` de la classe `ColorPalette` 
*code original :*
```python
mpl_palette = plt.get_cmap(palette_name, color_count)
colors = [
    Color(int(r * 255), int(g * 255), int(b * 255))
    for r, g, b, _ in mpl_palette.colors
]
return cls(colors)
```

*code corrigé  depuis une version plus récente de supervision :*
```python
        if hasattr(mpl_palette, "colors"):
            colors = mpl_palette.colors
        else:
            colors = [mpl_palette(i / (color_count - 1)) for i in range(color_count)]

        return cls(
            [Color(int(r * 255), int(g * 255), int(b * 255)) for r, g, b, _ in colors]
        )
```

Le problème venait du fait que l’objet `LinearSegmentedColormap` de Matplotlib n’a pas d’attribut `.colors`. Cet attribut existe seulement dans certains types de palettes qui stockent une liste fixe de couleurs.
`LinearSegmentedColormap` génère les couleurs par interpolation continue, donc il faut échantillonner la palette en plusieurs points pour obtenir une liste discrète de couleurs.

- génération de [[ByteTrack12.mp4]] avec [[Programmes/ByteTrack/VuPhan/adaptation.py|adaptation.py]] : légère modification des hyperparamètres du tracker
```python
self.byte_tracker = ByteTrack(
	track_activation_threshold=0.45,
	lost_track_buffer=300,               # 1s à 60 fps
	minimum_matching_threshold=0.7,
	frame_rate=60
)
```

- implémentation d'un switch/case qui permet de jouer sur la sortie obtenue (vidéo par défaut, avec le fond original, un fond blanc ou noire, ou alors génération supplémentaire d'un json).

- génération de [[ByteTrack11-b.mp4]] avec [[Programmes/ByteTrack/VuPhan/adaptation.py|adaptation.py]] : 41s
- génération de [[ByteTrack11-w.mp4]] avec [[Programmes/ByteTrack/VuPhan/adaptation.py|adaptation.py]] : 39s
- génération de [[ByteTrack11-o.mp4]] avec [[Programmes/ByteTrack/VuPhan/adaptation.py|adaptation.py]] 

- - génération de [[ByteTrack13.mp4]] avec [[Programmes/ByteTrack/VuPhan/adaptation.py|adaptation.py]] : 
```python
self.byte_tracker = ByteTrack(
	track_activation_threshold=0.45,
	lost_track_buffer=300,               # 1s à 60 fps
	minimum_matching_threshold=0.8,
	frame_rate=60
)
```

---
## Problèmes
- [[ByteTrack11.mp4]] : (47s) Changement automatique par méthode intégrée efficace. Toujours **1609 individus différents** détectés.
- [[ByteTrack12.mp4]] : (50s) Résultats identiques à [[ByteTrack11.mp4]] sur les frame 1 et **2676 individus** détectés. 
- Depuis le début des essais, ByteTrack et DeepSORT, je lancais le script sur [[Out_UP_Extrait1_15s.mp4]] (vidéo avec bbox YOLO) plutôt que sur [[UP_Extrait1_15s.mp4]]. Ce qui change considérablement les résultats. Il est donc nécessaire de re-procéder au benchmark. 

- [[ByteTrack7.mp4]] : (72s) **1 038** détections jugées différentes.